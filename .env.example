# RAG MCP Server Configuration
# Copy this file to .env and fill in your values

# ===== Required API Keys =====
# OpenAI API Key (required for embeddings and LLM)
OPENAI_API_KEY=your_openai_api_key_here

# Search API Key (required for web search)
# Use Perplexity API key if SEARCH_BACKEND=perplexity
# Use Exa API key if SEARCH_BACKEND=exa
SEARCH_API_KEY=your_search_api_key_here

# ===== Optional API Configuration =====
# OpenAI Base URL (optional, for proxy or alternative endpoints)
# OPENAI_BASE_URL=https://api.openai.com/v1

# Search Base URL (optional, for proxy or alternative endpoints)
# For Perplexity: https://api.perplexity.ai
# For Exa: https://api.exa.ai
# SEARCH_BASE_URL=https://api.perplexity.ai

# ===== Search Backend Configuration =====
# Choose search backend: 'perplexity' or 'exa'
# perplexity: Best for research & comprehensive answers
# exa: Best for semantic search & AI-optimized content
SEARCH_BACKEND=perplexity

# ===== Environment Configuration =====
# Environment: dev, test, prod
ENVIRONMENT=dev

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ===== Vector Store Configuration =====
# Path to vector store database
VECTOR_STORE_PATH=./data/vector_store.db

# Collection name for documents
COLLECTION_NAME=rag_documents

# ===== Search & Similarity Configuration =====
# Similarity threshold for matching (0.0-1.0)
SIMILARITY_THRESHOLD=0.75

# Number of similar documents to retrieve
SIMILARITY_TOP_K=10

# Minimum similarity score for search results (0.0-1.0)
SIMILARITY_CUTOFF=0.7

# ===== LlamaIndex Configuration =====
# Enable LlamaIndex for enhanced RAG processing
USE_LLAMAINDEX=true

# Text chunk size for document processing
CHUNK_SIZE=1024

# Overlap between text chunks
CHUNK_OVERLAP=200

# OpenAI embedding model
EMBEDDING_MODEL=text-embedding-3-small

# ===== Network & Performance Configuration =====
# Maximum retry attempts for failed requests
MAX_RETRIES=3

# Request timeout in seconds
TIMEOUT_SECONDS=30

# ===== Rate Limiting Configuration =====
# Enable request rate limiting
ENABLE_RATE_LIMITING=true

# Maximum requests per time window
RATE_LIMIT_REQUESTS=100

# Time window in seconds for rate limiting
RATE_LIMIT_WINDOW=60

# ===== System Components Configuration =====
# Enable Prometheus metrics collection
ENABLE_PROMETHEUS_METRICS=true

# Use loguru for structured logging
USE_LOGURU=true

# Enable tenacity-based retry logic
ENABLE_RETRY_LOGIC=true